{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization of Complex Agro-Environmental Data\n",
    "---\n",
    "### Exercise #5 - correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import seaborn as sns # For plotting\n",
    "import matplotlib.pyplot as plt # For showing plots\n",
    "import scipy.stats as sts\n",
    "import scikit_posthocs as sp\n",
    "import statsmodels.stats as stm\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../examples/EFIplus_medit.zip',compression='zip', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the dataset to remove unnecessary columns (eg. REG) \n",
    "df.drop(df.iloc[:,5:15], axis=1, inplace=True)\n",
    "\n",
    "# let's rename some columns so that they make sense\n",
    "df.rename(columns={'Sum of Run1_number_all':'Total_fish_individuals'}, inplace=True) # inplace=\"True\" means that df will be updated\n",
    "\n",
    "# for sake of consistency, let's also make all column labels of type string\n",
    "df.columns = list(map(str, df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a good way of detecting missing values in the dataset\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.heatmap(df.isnull(),cbar=False,cmap='viridis',yticklabels=False)\n",
    "plt.title('Missing values (yellow) in the dataset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() # drops rows when at least one element is a missing value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the Mean Annual Temperature\n",
    "df['temp_ann_st'] = (df['temp_ann'] - df['temp_ann'].mean()) / df['temp_ann'].std()\n",
    "df['temp_ann_st']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpler alternative\n",
    "sts.zscore(df['temp_ann'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tst_mean = round(df['temp_ann_st'].mean())\n",
    "Tst_SD = df['temp_ann_st'].std()\n",
    "\n",
    "# standard error\n",
    "SE = Tst_SD/math.sqrt(len(df))\n",
    "\n",
    "# Compute the 95% CI manually \n",
    "lower = Tst_mean-1.96*SE\n",
    "upper = Tst_mean+1.96*SE\n",
    "print('95% CI:', (lower, upper))\n",
    "\n",
    "# Alternative using the scipy function norm.interval\n",
    "CI = sts.norm.interval(0.95, Tst_mean, scale=SE)\n",
    "print('95% CI:', CI)\n",
    "\n",
    "# Assuming a t-distribution instead\n",
    "CI_t = sts.t.interval(confidence=0.95, df=len(df)-1, loc=Tst_mean, scale=SE)\n",
    "print('95% CI t distribution:', CI_t)\n",
    "\n",
    "print(Tst_mean)\n",
    "print(Tst_SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['temp_ann'])\n",
    "sns.histplot(df['temp_ann_st'], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df,x='Salmo trutta fario',y='temp_ann_st')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run t test\n",
    "# H0 : The samples are drawn from populations with equal means\n",
    "\n",
    "sample1 = df[df['Salmo trutta fario']==0]['temp_ann_st']\n",
    "sample2 = df[df['Salmo trutta fario']==1]['temp_ann_st']\n",
    "\n",
    "print('Mean of sample 1 = ', sample1.mean())\n",
    "print('Mean of sample 2 = ', sample2.mean())\n",
    "\n",
    "# t-test - tests the null hypothesis that sample 1 and 2 are derived from populations with the same mean\n",
    "stat, p = sts.ttest_ind(sample1, sample2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p)) # print outputs\n",
    "alpha=0.05\n",
    "if p > alpha:\n",
    " print('fail to reject H0. Rejecting H0 has an error probability >0.05')\n",
    "else:\n",
    " print('reject H0 with an error probability <0.05)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_count = pd.crosstab(index = df['Catchment_name'], columns='count')\n",
    "catchment_count.sort_values(by=['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "dfsub = df2[(df2['Catchment_name']=='Galiza-Norte') | \n",
    "    (df2['Catchment_name']=='Minho') |\n",
    "    (df2['Catchment_name']=='Cantabrica') |\n",
    "    (df2['Catchment_name']=='Douro') |\n",
    "    (df2['Catchment_name']=='Tejo') |\n",
    "    (df2['Catchment_name']=='Guadia') |\n",
    "    (df2['Catchment_name']=='Galiza-Sul') |\n",
    "    (df2['Catchment_name']=='Mondego')\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Actual_river_slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "qqplot(pd.Series(df2['Elevation_mean_catch']), line='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although the distribution of the mean elevation is right skewed and seems to depart from normality we will nevertheless try to run ANOVA. \n",
    "\n",
    "mod = ols('Elevation_mean_catch ~ Catchment_name',\n",
    "                data=dfsub).fit()\n",
    "                \n",
    "aov_table = sm.stats.anova_lm(mod, typ=2) # typ is the type of anova type to perform ('I','II' or 'III' = 1,2,3)\n",
    "print(aov_table) # provides the usual ANOVA table\n",
    "\n",
    "alpha=0.05\n",
    "p=aov_table['PR(>F)'][0]\n",
    "\n",
    "if p <= alpha:\n",
    " print('reject H0 that mean elevation values are equal among catchments')\n",
    "else:\n",
    " print('fail to reject H0 that mean elevation values are equal among catchments')\n",
    "\n",
    "# compute mean elevation for eacch catchment\n",
    "dfsub[['Elevation_mean_catch','Catchment_name']].groupby('Catchment_name').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple comparisons - perform Tukey's test \n",
    "tukey = stm.multicomp.pairwise_tukeyhsd(endog=dfsub['Elevation_mean_catch'],\n",
    "                          groups=dfsub['Catchment_name'],\n",
    "                          alpha=0.05)\n",
    "#display results\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dfsub, x='Catchment_name', y='Actual_river_slope')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5.4\n",
    "\n",
    "Potential problems in the data used for hypothesis testing are: \n",
    "- Departure from the normal distribution\n",
    "- Categories are highly unbalanced (very different number of samples for each category - see below). \n",
    "- Lack of independency among sampling sites. For example when we tested the effect of Actual_river_slope in the presence of Salmo trutta fario, we did not take into account that observations within each catchment might not be totally independent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfsub['Catchment_name'].value_counts())\n",
    "print(df['Salmo trutta fario'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization of Complex Agro-Environmental Data\n",
    "---\n",
    "### Exercise #6 - correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import seaborn as sns # For plotting\n",
    "import matplotlib.pyplot as plt # For showing plots\n",
    "import scipy.stats as sts\n",
    "import scikit_posthocs as sp\n",
    "import statsmodels.stats as stm\n",
    "from statsmodels.graphics.gofplots import qqplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6.1 Using the EFIplus_medit.zip dataset, test if the frequency of sites with presence and absence of Salmo trutta fario (Brown Trout) are independent from the country. Please state which is/are the null hypothesis of your test(s). You may try to produce an alluvial plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../examples/EFIplus_medit.zip',compression='zip', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the dataset to remove unnecessary columns (eg. REG) \n",
    "df.drop(df.iloc[:,5:15], axis=1, inplace=True)\n",
    "\n",
    "# let's rename some columns so that they make sense\n",
    "df.rename(columns={'Sum of Run1_number_all':'Total_fish_individuals'}, inplace=True) # inplace=\"True\" means that df will be updated\n",
    "\n",
    "# for sake of consistency, let's also make all column labels of type string\n",
    "df.columns = list(map(str, df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce contingency table of Country and Samo trutta fario.\n",
    "cdf = pd.crosstab(index=df['Country'], columns=df['Salmo trutta fario'])\n",
    "print(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test of independency\n",
    "stat, p, dof, expected = sts.chi2_contingency(cdf)\n",
    "print('df=%d' % dof)\n",
    "print('expected values:')\n",
    "print(expected)\n",
    "\n",
    "# Alternative 1: interpret based on test-statistic\n",
    "prob=0.95\n",
    "critical = sts.chi2.ppf(prob, dof)\n",
    "print('critical=%.3f, stat=%.3f' % (critical, stat))\n",
    "if abs(stat) >= critical:\n",
    " print('stat > critical => reject H0 that variables are independent')\n",
    "else:\n",
    " print('stat < critical => fail to reject H0 that variables are independent')\n",
    "\n",
    " # Alternative 2: interpret based on p-value\n",
    "alpha = 0.05\n",
    "print('significance=%.2f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    " print('reject H0 that variables are independent')\n",
    "else:\n",
    " print('fail to reject H0 that variables are independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6.2 Run the non-parametric equivalent of the test you used in exercise 5.3 and compare with the ANOVA test (5.2: Test whether there are differences in the mean elevation in the upstream catchment (Elevation_mean_catch) among the eight most sampled catchments. For which pairs of catchments are these diferences significant? Please state which is/are the null hypothesis of your test(s)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with at least one missing value\n",
    "df.dropna(subset=['Elevation_mean_catch'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run histogram\n",
    "sns.histplot(df['Elevation_mean_catch'])\n",
    "plt.show()\n",
    "\n",
    "# Run qq-plot\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "qqplot(pd.Series(df['Elevation_mean_catch']), line='q')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_count = pd.crosstab(index = df['Catchment_name'], columns='count')\n",
    "catch_top8 = catchment_count.sort_values(by=['count'], ascending=False).head(8).index.to_list()\n",
    "dfsub = df[df.Catchment_name.isin(catch_top8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.boxplot(data=dfsub, x='Catchment_name', y='Elevation_mean_catch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run non-parametric equivalent to one-way ANOVA - Kruskal-Walis test\n",
    "\n",
    "sample1 = df[(df['Catchment_name']=='Tejo')]['Elevation_mean_catch']\n",
    "sample2 = df[(df['Catchment_name']=='Douro')]['Elevation_mean_catch']\n",
    "sample3 = df[(df['Catchment_name']=='Ebro')]['Elevation_mean_catch']\n",
    "sample4 = df[(df['Catchment_name']=='Cantabrica')]['Elevation_mean_catch']\n",
    "sample5 = df[(df['Catchment_name']=='Guadia')]['Elevation_mean_catch']\n",
    "sample6 = df[(df['Catchment_name']=='Galiza-Norte')]['Elevation_mean_catch']\n",
    "sample7 = df[(df['Catchment_name']=='Minho')]['Elevation_mean_catch']\n",
    "sample8 = df[(df['Catchment_name']=='Catala')]['Elevation_mean_catch']\n",
    "\n",
    "\n",
    "stat, p = sts.kruskal(sample1, sample2, sample3, sample4, sample5, sample6, sample7, sample8)\n",
    "print('F-statistics=%.3f, p=%.6f' % (stat, p))\n",
    "\n",
    "alpha=0.05\n",
    "\n",
    "if p <= alpha:\n",
    " print('reject H0 that median elevation values are equal among catchments')\n",
    "else:\n",
    " print('fail to reject H0 that median elevation values are equal among catchments')\n",
    "\n",
    "# Compute median values of Mean elevation for each catchment\n",
    "dfsub[['Elevation_mean_catch','Catchment_name']].groupby('Catchment_name').median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Dunn test\n",
    "sp.posthoc_dunn(a=dfsub, val_col='Elevation_mean_catch', group_col= 'Catchment_name', p_adjust = 'bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "mod = ols('Elevation_mean_catch ~ Catchment_name',\n",
    "                data=dfsub).fit()\n",
    "                \n",
    "aov_table = sm.stats.anova_lm(mod, typ=2) # typ is the type of anova type to perform ('I','II' or 'III' = 1,2,3)\n",
    "print(aov_table) # provides the usual ANOVA table\n",
    "\n",
    "alpha=0.05\n",
    "p=aov_table['PR(>F)'][0]\n",
    "\n",
    "if p <= alpha:\n",
    " print('reject H0 that mean elevation values are equal among catchments')\n",
    "else:\n",
    " print('fail to reject H0 that mean elevation values are equal among catchments')\n",
    "\n",
    "# compute mean elevation for eacch catchment\n",
    "dfsub[['Elevation_mean_catch','Catchment_name']].groupby('Catchment_name').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple comparisons - perform Tukey's test \n",
    "tukey = stm.multicomp.pairwise_tukeyhsd(endog=dfsub['Elevation_mean_catch'],\n",
    "                          groups=dfsub['Catchment_name'],\n",
    "                          alpha=0.05)\n",
    "#display results\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 6.3 Using the winequality_red.csv file in the examples folder of the github repository, test which wine parameters discriminate the best between wine quality scores categorized into two classes using value 5 as the threshold value (quality>5=“good” and quality<5=“bad”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('../examples/winequality_red.csv')\n",
    "df_wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine['quality'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize quality values into \"good\" and \"bad\"\n",
    "df_wine['quality_class'] = pd.cut(x=df_wine['quality'], bins=[0, 5, 10], labels=[\"bad\",\"good\"]) # NOTE: the bins intervals are closed to the left (])\n",
    "pd.crosstab(index = df_wine['quality_class'], columns='count') # sample sizes are relatively balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df_wine.iloc[:,0:11].plot.box(subplots=True, legend=True, layout=(4, 3), figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too many outliers => better to run a Mann-Whitney U test (two-tailed) for each variable\n",
    "\n",
    "output_table = [] # define list of results\n",
    "\n",
    "# run loop to test for each variable\n",
    "for var in df_wine.columns[0:11]:\n",
    "    bad = df_wine[df_wine['quality_class'] == 'bad'][var]\n",
    "    good = df_wine[df_wine['quality_class'] == 'good'][var]\n",
    "    stat, p = sts.mannwhitneyu(good, bad) # run Mann-Whitney U test\n",
    "    output_table.append({'Variable': var,\n",
    "                        'U statistic': stat,\n",
    "                        'p-value': p}) # Append outputs\n",
    "\n",
    "print(pd.DataFrame(output_table))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
